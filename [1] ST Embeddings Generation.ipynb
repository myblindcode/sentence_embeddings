{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa15f878-883c-4c68-932d-9cda26e8dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f6a62d6-27fb-4cfb-8154-45155aff89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATASETS_PATH = '../DATASETS/'\n",
    "EMBEDDINGS_PATH = './EMBEDDINGS/'\n",
    "\n",
    "baseline_st_models = [\"sentence-transformers/all-MiniLM-L6-v2\", \"allenai/scibert_scivocab_uncased\"]\n",
    "\n",
    "datasets = [\n",
    "    {\n",
    "        \"dataset_desc\": \"CSAbstruct\",\n",
    "        \"dataset_path\": f\"{BASE_DATASETS_PATH}CSAbstruct/\",\n",
    "        \"file_prefix\": \"csabstruct\",\n",
    "        \"st_models\": [\"gubartz/st_minilm_abstruct\", \"gubartz/st_scibert_abstruct\"]\n",
    "    },\n",
    "    {\n",
    "        \"dataset_desc\": \"PubMed-RCT\",\n",
    "        \"dataset_path\": f\"{BASE_DATASETS_PATH}PubMed-RCT/\",\n",
    "        \"file_prefix\": \"pubmed_rct\",\n",
    "        \"st_models\": [\"gubartz/st_minilm_pubmed_rct\", \"gubartz/st_scibert_pubmed_rct\"]\n",
    "    },\n",
    "    {\n",
    "        \"dataset_desc\": \"PMC-Sents-FULL\",\n",
    "        \"dataset_path\": f\"{BASE_DATASETS_PATH}PMC-Sents-FULL/\",\n",
    "        \"file_prefix\": \"pmc_sents_full\",\n",
    "        \"st_models\": [\"gubartz/st_minilm_pmc_sents_full\", \"gubartz/st_scibert_pmc_sents_full\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2eed8a7-99e5-4a2f-9f7b-bb14237c75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(f'{EMBEDDINGS_PATH}embeddings_meta.jsonl'):\n",
    "    os.remove(f'{EMBEDDINGS_PATH}embeddings_meta.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17bc35fb-90f9-42e1-a41b-c4d55df0acdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0496ef879fd94dd7ba4bd110453075c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "pbar_datasets = tqdm(datasets)\n",
    "\n",
    "for dataset in pbar_datasets:\n",
    "    pbar_datasets.set_description(dataset['dataset_desc'])\n",
    "    \n",
    "    train_dataset = f\"{dataset['dataset_path']}{dataset['file_prefix']}_train.parquet\"\n",
    "    test_dataset = f\"{dataset['dataset_path']}{dataset['file_prefix']}_test.parquet\"   \n",
    "    \n",
    "    df_train = pd.read_parquet(train_dataset)\n",
    "    df_test = pd.read_parquet(test_dataset)\n",
    "    df_train['sentence'] = df_train['sentence']\n",
    "    df_test['sentence'] = df_test['sentence']\n",
    "    \n",
    "    # sort for less padding\n",
    "    df_train = df_train.sort_values(by=\"sentence\", key=lambda x: x.str.len())\n",
    "    df_test = df_test.sort_values(by=\"sentence\", key=lambda x: x.str.len())\n",
    "\n",
    "    train_sentences = list(df_train['sentence'].values)\n",
    "    test_sentences = list(df_test['sentence'].values)\n",
    "    \n",
    "    y_train_true = list(df_train['label_id'].values)\n",
    "    y_test_true = list(df_test['label_id'].values)    \n",
    "    \n",
    "    st_models = dataset['st_models'] + baseline_st_models\n",
    "    pbar_st_models = tqdm(st_models, leave=False)\n",
    "    \n",
    "    for st_model_id in pbar_st_models:\n",
    "        pbar_st_models.set_description(st_model_id)\n",
    "        \n",
    "        model_name = st_model_id.split(\"/\")[-1]\n",
    "        \n",
    "        st_model = SentenceTransformer(st_model_id, device='cuda')\n",
    "        \n",
    "        embeddings_train = st_model.encode(train_sentences,\n",
    "                                           show_progress_bar=True,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "        embeddings_test = st_model.encode(test_sentences,\n",
    "                                          show_progress_bar=True,\n",
    "                                          batch_size=batch_size)\n",
    "        # dump embeddings\n",
    "        file_name = f\"{dataset['dataset_desc']}_{model_name}.pickle\"\n",
    "\n",
    "        output_dict = {'embeddings_train': embeddings_train,\n",
    "                       'embeddings_test': embeddings_test,\n",
    "                       'y_train_true': y_train_true,\n",
    "                       'y_test_true': y_test_true}\n",
    "        with open(f\"{EMBEDDINGS_PATH}{file_name}\", 'wb') as pfile:\n",
    "            pickle.dump(output_dict, pfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        embedding_meta = {'dataset_desc': dataset['dataset_desc'],\n",
    "                          'model_name': model_name,\n",
    "                          'file_name': file_name}\n",
    "        \n",
    "        with open(f'{EMBEDDINGS_PATH}embeddings_meta.jsonl', 'a', encoding=\"utf-8\") as outfile:\n",
    "            outfile.write(json.dumps(embedding_meta))\n",
    "            outfile.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
